#include "ooo_cpu.h"
#include <bitset>

#define GLOBAL_HISTORY_LENGTH   1000
#define CLOCK_RESET_LIMIT       256000  // 256k as in paper

#define BIMODAL_SIZE            16      // 2^16 : Num entries in bimodal table
#define TAGE_SIZE               12      // 2^12 : Num entries in tage table

#define NUM_TAGE_TABLES         4
#define BIMODAL_PRED_SIZE       2       // Pred variable in Bimodal table
#define TAGE_PRED_SIZE          3       // Pred variable in tage table
#define TAGE_USEFUL_SIZE        2       // Useful variable in tage table
#define TAGE_TAG_SIZE           8       // Tag variable in tage table

#define BIMODAL_MAX             3   // b(11)
#define TAGE_MAX                7   // b(111)
#define BIMODAL_WEAKLY_TAKEN    2   // 2 bit
#define TAGE_WEAKLY_TAKEN       4   // 3 bit

// TODO: Change this (length of history for indexing on tage tables)
#define TAGE_HISTORY_1          5
#define TAGE_HISTORY_2          15
#define TAGE_HISTORY_3          44
#define TAGE_HISTORY_4          130

#define CLOCK_STATE_1           1   // reset LSB of u
#define CLOCK_STATE_2           2   // reset MSB of u

#define TAKEN                   1
#define NOT_TAKEN               0

typedef struct bimodalEntry {
    uint8_t pred : BIMODAL_PRED_SIZE;
} bimodal_t;

typedef struct tageEntry {
    uint8_t pred : TAGE_PRED_SIZE;
    uint8_t use : TAGE_USEFUL_SIZE;
    uint8_t tag : TAGE_TAG_SIZE;
} tage_t;

typedef struct prediction {
    uint8_t pred;
    uint8_t altPred;
    uint8_t index;
    uint8_t altIndex;
    uint8_t table;
    uint8_t altTable;
} prediction_t;

// Global data structures
bimodal_t bimodalTable[NUM_CPUS][1 << (BIMODAL_SIZE)];
tage_t tageTable[NUM_CPUS][NUM_TAGE_TABLES][1 << (TAGE_SIZE)];
prediction_t predict[NUM_CPUS];
uint32_t tageTag[NUM_TAGE_TABLES];
uint32_t tageIndex[NUM_TAGE_TABLES];
uint32_t global_clock;
uint8_t clockstate;


bitset<GLOBAL_HISTORY_LENGTH> history;

void O3_CPU::initialize_branch_predictor()
{
    cout << "CPU " << cpu << " LTAGE Branch Predictor\n";

    int bimodal_size = 1 << BIMODAL_SIZE;
    for (int i = 0; i < bimodal_size; ++i)
        bimodalTable[cpu][i].pred = BIMODAL_WEAKLY_TAKEN;
    
    int tage_size = 1 << TAGE_SIZE;
    memset(tageTable[cpu], 0, tage_size * sizeof(tage_t));
    history.reset();
}

uint8_t O3_CPU::predict_branch(uint64_t ip)
{
    uint8_t bimodalIndex = ip % (1 << BIMODAL_SIZE);

    // TODO: Initialize this properly
    bzero(tageTag, NUM_TAGE_TABLES * sizeof(int));
    bzero(tageTable, NUM_TAGE_TABLES * sizeof(int));

    predict[cpu].table = NUM_TAGE_TABLES;       // Init value = 4
    predict[cpu].altTable = NUM_TAGE_TABLES;    // Init value = 4

    // Check for tag hits (this will be the provider component)
    for (int i = NUM_TAGE_TABLES - 1; i >= 0; --i) {
        if (tageTable[cpu][i][tageIndex[i]].pred == tageTag[i]) {
            predict[cpu].table = i;
            predict[cpu].index = tageIndex[i];
            break;
        }
    }

    // Now, check for alternate prediction component
    for (int i = predict[cpu].table - 1; i >= 0; --i) {
        if (tageTable[cpu][i][tageIndex[i]].pred == tageTag[i]) {
            predict[cpu].altTable = i;
            predict[cpu].altIndex = tageIndex[i];
            break;
        }  
    }

    // If alternate prediction was not obtained, set altPred to Bimodal
    if (predict[cpu].altTable == NUM_TAGE_TABLES) {
        predict[cpu].altPred = (bimodalTable[cpu][bimodalIndex].pred >=
            BIMODAL_WEAKLY_TAKEN) ? TAKEN : NOT_TAKEN;
    } else {
        predict[cpu].altPred = (tageTable[cpu][predict[cpu].altTable]
            [predict[cpu].altIndex].pred >= TAGE_WEAKLY_TAKEN) ?
            TAKEN : NOT_TAKEN;
    }

    // If predictor component could not be found, set Pred to Bimodal
    if (predict[cpu].table == NUM_TAGE_TABLES) {
        predict[cpu].pred = predict[cpu].altPred;
    } else {
        predict[cpu].pred = (tageTable[cpu][predict[cpu].table]
            [predict[cpu].index].pred >= TAGE_WEAKLY_TAKEN) ? TAKEN : NOT_TAKEN;
    }

    return predict[cpu].pred;
}

void O3_CPU::last_branch_result(uint64_t ip, uint8_t taken)
{
    // Not a good idea to consume stack memory
    uint8_t predtable = predict[cpu].table;
    uint8_t predindex = predict[cpu].index;
    uint8_t bimodalIndex = ip % (1 << BIMODAL_SIZE);

    // Update global history
    history <<= 1;
    if (taken) history.set(0, 1); 

    // Update "u" bit in provider tagetable if altPred is different from pred
    if (predtable != NUM_TAGE_TABLES &&
        (predict[cpu].pred != predict[cpu].altPred)) {
        if (predict[cpu].pred == taken)
            ++(tageTable[cpu][predtable][predindex].use);
        else
            --(tageTable[cpu][predtable][predindex].use);    
    }

    // Updates on a correct branch prediction
    // TODO: Optimizations for newly allocated entries
    if (predict[cpu].pred == taken) {
        if (predtable != NUM_TAGE_TABLES) {
            // One of the tage table was the provider component
            if (tageTable[cpu][predtable][predindex].pred < TAGE_MAX)
                ++(tageTable[cpu][predtable][predindex].pred);
        } else {
            // Bimodal table was the provider component, update pred value
            if (bimodalTable[cpu][bimodalIndex].pred < BIMODAL_MAX)
                ++(bimodalTable[cpu][bimodalIndex].pred);
        }
    } else {    // Our prediction was incorrect
        // STEP 1: Update the pred value in provider component
        if (predtable != NUM_TAGE_TABLES) {
            // One of the tage table was the provider component
            if (tageTable[cpu][predtable][predindex].pred > 0)
                --(tageTable[cpu][predtable][predindex].pred);
        } else {
            // Bimodal table was the provider component, update pred value
            if (bimodalTable[cpu][bimodalIndex].pred > 0)
                --(bimodalTable[cpu][bimodalIndex].pred);
        }

        // STEP 2: Check arrangements for entry allocation
        // Check if the provider table is the longest history table. If not,
        // then an entry can be allocated.
        if (predtable != NUM_TAGE_TABLES - 1) {
            if (predtable == NUM_TAGE_TABLES) predtable = -1;
            
            // TODO: Implement "rule B" of TAGE paper.
            //
            // Keep track of entries with u = 0.
            // bitset<NUM_TAGE_TABLES> allocTable;
            uint8_t uflag = NUM_TAGE_TABLES;
            for (int i = predtable + 1; i < NUM_TAGE_TABLES; ++i) {
                if (tageTable[cpu][i][tageIndex[i]].use == 0) uflag = i;
            }
            // If no useful bit was zero then decrement them all by 1.
            // Else allocate a new entry for the same.
            if (uflag != NUM_TAGE_TABLES) {
                tageTable[cpu][uflag][tageIndex[uflag]].tag = tageTag[uflag];
                tageTable[cpu][uflag][tageIndex[uflag]].use = 0;
                tageTable[cpu][uflag][tageIndex[uflag]].pred = TAGE_WEAKLY_TAKEN;
            } else {
                for (int i = predtable + 1; i < NUM_TAGE_TABLES; ++i) {
                    --(tageTable[cpu][i][tageIndex[i]].use);
                    assert(tageTable[cpu][i][tageIndex[i]].use >= 0);
                }
            }
        }
    }

    // Global clock handling: Check if it is time to flip bits of "u"
    if ((++global_clock) == CLOCK_RESET_LIMIT) {
        clockstate = (clockstate == CLOCK_STATE_1) ? CLOCK_STATE_2 : CLOCK_STATE_1;
        global_clock = 0;

        // Reset either MSB or LSB of u for depending on CLOCK_STATE
        for (int i = 0; i < NUM_TAGE_TABLES; ++i) {
            for (int j = 0; j < (1 << TAGE_SIZE); ++j)
                tageTable[cpu][i][j].use &= clockstate;
        }
    }

}
